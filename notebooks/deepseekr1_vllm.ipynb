{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Workshop Tutorial: Leveraging AMD GPUs with DeepSeek-R1\n",
    "\n",
    "Welcome to this hands-on workshop! Throughout this tutorial, we'll leverage AMD GPUs to deploy powerful language models like DeepSeek-R1. We'll cover setting up an AI development environment and explore three main practical applications:\n",
    "\n",
    "1. **Advanced Chatbot:** Using Open WebUI to create a sophisticated chatbot with web search and file interaction capabilities.\n",
    "2. **Code Development Assistant:** Installing and utilizing the CodeGPT VS Code extension to perform code analysis and pair programming tasks.\n",
    "3. **Web-Based AI Agent:** Deploying a web agent capable of autonomous web browsing connected to our custom AI endpoint.\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Step 1: Access AMD GPUs](#step1)\n",
    "- [Step 2: Docker Installation and Configuration](#step2)\n",
    "- [Step 3: Launching vLLM Server on AMD GPUs](#step3)\n",
    "- [Step 4: Advanced Chatbot with Open WebUI](#step4)\n",
    "- [Step 5: Chatbot Testing with DeepSeek-R1](#step5)\n",
    "- [Step 6: Code Development Assistant Using CodeGPT](#step6)\n",
    "- [Step 7: Build a Snake Game with CodeGPT](#step7)\n",
    "- [Step 8: Optional Advanced Challenge - Pac-Man](#step8)\n",
    "- [Step 9: Deploying Your Web-Based AI Agent](#step9)\n",
    "\n",
    "<a id=\"step1\"></a>\n",
    "\n",
    "## Step 1: Access AMD GPUs\n",
    "\n",
    "- **For Developers:** Request access via AMD’s Developer Cloud application [here](https://www.amd.com/en/forms/registration/developer-cloud-application.html).\n",
    "- **Enterprise Users:** Check out AMD’s cloud partners [here](https://www.amd.com/en/developer/resources/rocm-hub/dev-ai.html).\n",
    "\n",
    "<a id=\"step2\"></a>\n",
    "\n",
    "## Step 2: Docker Installation and Configuration\n",
    "Ensure Docker is installed and properly configured on your system. Follow [Docker's official installation guide](https://docs.docker.com/get-docker/) if necessary.\n",
    "\n",
    "**Docker Permissions:**\n",
    "\n",
    "Allow non-root Docker access by running:\n",
    "\n",
    "```bash\n",
    "sudo usermod -aG docker $USER\n",
    "newgrp docker\n",
    "```\n",
    "\n",
    "Verify Docker installation:\n",
    "\n",
    "```bash\n",
    "docker run hello-world\n",
    "```\n",
    "\n",
    "<a id=\"step3\"></a>\n",
    "\n",
    "## Step 3: Launching vLLM Server on AMD GPUs\n",
    "### Start vLLM Docker Container\n",
    "Launch an interactive vLLM Docker container:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm \\\n",
    "  --network=host \\\n",
    "  --device=/dev/kfd \\\n",
    "  --device=/dev/dri \\\n",
    "  --group-add=video \\\n",
    "  --ipc=host \\\n",
    "  --cap-add=SYS_PTRACE \\\n",
    "  --security-opt seccomp=unconfined \\\n",
    "  --shm-size 16G \\\n",
    "  rocm/vllm-dev:main\n",
    "```\n",
    "\n",
    "### Deploy DeepSeek-R1 Model with vLLM\n",
    "Run the following commands within your Docker container to start the vLLM server:\n",
    "\n",
    "```bash\n",
    "export VLLM_SEED=42\n",
    "export VLLM_MLA_DISABLE=0\n",
    "export VLLM_USE_TRITON_FLASH_ATTN=0\n",
    "export VLLM_USE_ROCM_FP8_FLASH_ATTN=0\n",
    "export VLLM_FP8_PADDING=1\n",
    "export VLLM_USE_AITER_MOE=1\n",
    "export VLLM_USE_AITER_BLOCK_GEMM=1\n",
    "export VLLM_USE_AITER_MLA=0\n",
    "\n",
    "vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port PORT_NUMBER \\\n",
    "    --api-key abc-123 \\\n",
    "    --trust-remote-code \\\n",
    "    --seed 42\n",
    "```\n",
    "\n",
    "**Note:** Select an appropriate port number that is open to the public. Ensure network and firewall settings allow connections to your server via selected port number.\n",
    "\n",
    "Upon successful launch, your server should be accepting incoming traffic through an OpenAI-compatible API. Retrieve the public IP address of your server (typically available from your cloud provider's dashboard or by running `curl ifconfig.me` within the container or server shell). Verify the endpoint's reachability by executing the following from your local laptop:\n",
    "\n",
    "```\n",
    "curl http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1/models -H \"Authorization: Bearer abc-123\"\n",
    "```\n",
    "\n",
    "<a id=\"step4\"></a>\n",
    "\n",
    "## Step 4: Advanced Chatbot with Open WebUI\n",
    "Follow the installation instructions from the [Open WebUI GitHub repository](https://github.com/open-webui/open-webui).\n",
    "\n",
    "After installation, configure your endpoint URL in the Open WebUI client as follows:\n",
    "\n",
    "- Navigate to `Settings` as shown in the image below:\n",
    "\n",
    "![OpenWebUI Setup 1](assets/openwebui1.png)\n",
    "\n",
    "- Select `Connections` form the left tab.\n",
    "  - Enter URL that is matching this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1`\n",
    "  - Enter `API Key` matching the key you chose in step 3 and passed to `vllm serve`.\n",
    "  - Enter model name that matches exactly the argument passed to `vllm serve` in step 3. For example `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`. \n",
    "  - Click on `+` button.\n",
    "  - Click on `Save` button. \n",
    "\n",
    "![OpenWebUI Setup 1](assets/openwebui2.png)\n",
    "\n",
    "\n",
    "<a id=\"step5\"></a>\n",
    "\n",
    "## Step 5: Chatbot Testing with DeepSeek-R1\n",
    "Use Open WebUI to interact with your chatbot. Example prompt:\n",
    "\n",
    "```\n",
    "Imagine facing east. Turn 90° left, then 270° right, then 180° left. Which direction are you facing?\n",
    "```\n",
    "\n",
    "Follow up with a request for code visualization:\n",
    "\n",
    "```\n",
    "Can you give me a simple python code without importing external libraries to visualize this step-by-step with Unicode arrows?\n",
    "```\n",
    "\n",
    "![OpenWebUI Example](assets/webui_example.gif)\n",
    "\n",
    "<a id=\"step6\"></a>\n",
    "\n",
    "## Step 6: Code Development Assistant Using CodeGPT or VS Code AI Toolkit\n",
    "### For CodeGPT (This extentsion might not be functional in certain countries):\n",
    "Install the CodeGPT extension in VS Code:\n",
    "- Open VS Code\n",
    "- Navigate to Extensions (`Ctrl+Shift+X`)\n",
    "- Search and install **CodeGPT**\n",
    "- Configure the extension with your custom endpoint URL to connect with your DeepSeek-R1 deployment.\n",
    "\n",
    "Configure your endpoint URL in the Open WebUI client as follows:\n",
    "\n",
    "- Create an account.\n",
    "- Once logged in select view more as shown in the image below: \n",
    "\n",
    "![CodeGPT Setup 1](assets/codegpt_setup1.png)\n",
    "\n",
    "- Select LLMs Cloud Model tab \n",
    "- Under `Select Provider` select `Custom`\n",
    "- Under `Select model` enter model name that matches exactly the argument passed to `vllm serve` in step 3. For example `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`.\n",
    "- Under `Connect to Custom`:\n",
    "  - Enter `API Key` matching the key you chose in step 3 and passed to `vllm serve`.\n",
    "  - Enter `Custom Link` matching this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1/chat/completions`\n",
    "\n",
    "![CodeGPT Setup 2](assets/codegpt_setup2.png)\n",
    "\n",
    "### For VS Code AI Toolkit \n",
    "Install the AI Toolkit for VS Code extension in VS Code:\n",
    "- Open VS Code\n",
    "- Navigate to Extensions (`Ctrl+Shift+X`)\n",
    "- Search and install **VS Code AI Toolkit**\n",
    "- Click on `remote inference` as shown in the image below:\n",
    "\n",
    "![AI Toolkit Setup 1](assets/aitoolkit1.png)\n",
    "\n",
    "- Select `Add a custom model`\n",
    "\n",
    "![AI Toolkit Setup 2](assets/aitoolkit2.png)\n",
    "\n",
    "- Enter Open AI compatible URL matching this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1/chat/completions`\n",
    "\n",
    "![AI Toolkit Setup 3](assets/aitoolkit_url.png)\n",
    "\n",
    "- Enter model name that matches exactly the argument passed to `vllm serve` in step 3. For example `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`.\n",
    "\n",
    "![AI Toolkit Setup 4](assets/aitoolkit3.png)\n",
    "\n",
    "- Press enter to display the model name as is. \n",
    "\n",
    "![AI Toolkit Setup 5](assets/aitoolkit5.png)\n",
    "\n",
    "- Enter HTTP header for authorization matching this format `Authorization: Bearer API KEY` exactly as specified here where `API Key` must match the key you chose in step 3 and passed to `vllm serve`. If you use the exact same command provided in this tutorials enter this `Authorization: Bearer abc-123`.\n",
    "\n",
    "![AI Toolkit Setup 6](assets/aitoolkit6.png)\n",
    "\n",
    "Once you've completed the steps above, your model should appear listed under `My MODELS` on the left. Click your model to start the corresponding playground.\n",
    "\n",
    "![AI Toolkit Setup 7](assets/aitoolkit.png)\n",
    "\n",
    "<a id=\"step7\"></a>\n",
    "\n",
    "## Step 7: Build a Snake Game with CodeGPT\n",
    "In VS Code, request:\n",
    "\n",
    "```\n",
    "\"Can you build a classic snake game? Include 'Powered by DeepSeek-R1 on AMD MI300X' in the corner. Use Python.\"\n",
    "```\n",
    "\n",
    "Run the generated code and enjoy your game!\n",
    "\n",
    "![CodeGPT Generated Snake Game](assets/snake.gif)\n",
    "\n",
    "<a id=\"step8\"></a>\n",
    "\n",
    "## Step 8: Optional Advanced Challenge - Pac-Man\n",
    "Try building a Pac-Man game with a maximum of three prompts. Here's an example built with a single prompt (DeepSeekR1 671B):\n",
    "\n",
    "![CodeGPT Generated Pacman with Single Prompt](assets/pacman.gif)\n",
    "\n",
    "<a id=\"step9\"></a>\n",
    "\n",
    "## Step 9: Deploying Your Web-Based AI Agent\n",
    "Clone our customized fork from this [GitHub Repository](https://github.com/Mahdi-CV/web-ui-sglang-vllm-deepseekr-fork).\n",
    "\n",
    "Once you start the agent on your web browser, follow the steps below to connect it to our vLLM server:\n",
    "- Select the `Agent Settings` tab and make sure to uncheck `Use Vision` since this model does not accept images as input.\n",
    "\n",
    "![Agent Setup 1](assets/agent1.png)\n",
    "\n",
    "- Select `LLM Configuration` tab.\n",
    "  - Select `openai` as your `LLM Provider`.\n",
    "  - Type model name that matches exactly the argument passed to `vllm serve` in step 3. For example `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`.\n",
    "  - Enter URL that is matching this format: `http://YOUR_SERVER_PUBLIC_IP:PORT_NUMBER/v1`.\n",
    "  - Enter `API Key` matching the key you chose in step 3 and passed to `vllm serve`.\n",
    "\n",
    "![Agent Setup 2](assets/agent2.png)\n",
    "\n",
    "- Select the `Browser Settings` tab and enable Headless Mode`.\n",
    "\n",
    "![Agent Setup 3](assets/agent3.png)\n",
    "\n",
    "- Select `Run Agent` tab and give the agent a task to complete.\n",
    "\n",
    "![Agent Setup 4](assets/agent4.png)\n",
    "\n",
    "\n",
    "Follow the README instructions to install, configure, and launch the agent. Explore the examples below:\n",
    "\n",
    "**Example 1:** Finding the most popular trending Hugging Face text-to-image model and generating a sample image:\n",
    "\n",
    "![Web Agent Hugging Face Example](assets/hf_webagent.gif)\n",
    "\n",
    "**Example 2:** Online shopping by gathering recipe ingredients and placing them in my shopping cart:\n",
    "\n",
    "![Web Agent Dinner Recipe Shopping Example](assets/dinner_webagent.gif)\n",
    "\n",
    "---\n",
    "\n",
    "Happy coding! If you encounter issues or have questions, don’t hesitate to ask during the workshop!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
